# üß† Debug Buddy ‚Äî IA para An√°lise de Logs Python/Django

## üéØ Objetivo do Projeto

Criar um agente de IA que auxilie desenvolvedores fullstack a identificar e interpretar logs de erro em aplica√ß√µes Python/Django, economizando tempo, melhorando a compreens√£o de exce√ß√µes e sugerindo poss√≠veis solu√ß√µes.

## üîç Problema Identificado

Desenvolvedores frequentemente perdem tempo tentando entender logs de erro complexos, especialmente quando envolvem stacktraces extensos, erros de template ou problemas em queries.

O Debug Buddy resolve isso analisando o log com IA e retornando:
- Resumo do erro
- Explica√ß√£o t√©cnica
- Causas prov√°veis
- Sugest√µes de solu√ß√£o

## ‚öôÔ∏è Como Funciona

1. O usu√°rio cola um log no campo da interface.
2. O sistema envia o log para a API da OpenAI com um prompt cuidadosamente constru√≠do.
3. A resposta da IA √© exibida diretamente ao usu√°rio.
4. Cada an√°lise √© salva no banco de dados.

## ü§ñ Prompt Utilizado

```
Voc√™ √© um engenheiro de software experiente. Abaixo est√° um log de erro Python/Django.

Sua tarefa √© analisar o log e retornar um relat√≥rio com:
1. ERRO IDENTIFICADO: Um resumo em uma linha do erro principal.
2. EXPLICA√á√ÉO: O que significa este erro?
3. POSS√çVEIS CAUSAS: 2-3 raz√µes pelas quais isso pode acontecer.
4. SUGEST√ïES: Como corrigir ou investigar o problema.

Por favor, responda em portugu√™s.

Log:
[log_here]
```

O prompt foi projetado para ser claro, direto e focado em retorno √∫til e acion√°vel.

## üß± Stack Utilizada

- **Backend**: Python + Django
- **Frontend**: Django Templates (HTML/CSS/JS)
- **IA**: OpenAI API (GPT-4)
- **Banco de Dados**: SQLite (padr√£o do Django)

## üõ†Ô∏è Como a IA Ajudou no Desenvolvimento

- Refinar prompts
- Corrigir exce√ß√µes no Django
- Sugerir estrutura de pastas
- Criar layout clean para a UI

## üí° Desafios Enfrentados

| Desafio | Solu√ß√£o |
|---------|---------|
| Excesso de retorno da API | Ajustei max_tokens e refinei o prompt |
| Layout inicial mal posicionado | Reescrevi o CSS para uma estrutura responsiva e centralizada |
| Entendimento dos requisitos do desafio | Estruturei a entrega com base no enunciado e crit√©rios |

## üìé Entreg√°veis

- Web App funcional com interface limpa
- Armazenamento de logs analisados
- Prompt bem estruturado
- C√≥digo organizado
- Documenta√ß√£o (este arquivo)

## üöÄ Instala√ß√£o e Configura√ß√£o

### Pr√©-requisitos

- Python 3.8 ou superior
- pip (gerenciador de pacotes Python)

### Passos para Instala√ß√£o

1. Clone o reposit√≥rio:
   ```
   git clone https://github.com/seu-usuario/debug-buddy.git
   cd debug-buddy
   ```

2. Crie e ative um ambiente virtual:
   ```
   python -m venv venv
   venv\Scripts\activate  # No Windows
   source venv/bin/activate  # No Linux/Mac
   ```

3. Instale as depend√™ncias:
   ```
   pip install -r requirements.txt
   ```

4. Crie um arquivo `.env` na raiz do projeto com sua chave da API OpenAI:
   ```
   OPENAI_API_KEY=sua-chave-api-aqui
   ```

5. Execute as migra√ß√µes do banco de dados:
   ```
   python manage.py migrate
   ```

6. Inicie o servidor de desenvolvimento:
   ```
   python manage.py runserver
   ```

7. Acesse a aplica√ß√£o em seu navegador:
   ```
   http://127.0.0.1:8000/
   ```

## üìã Uso da Aplica√ß√£o

1. Na p√°gina inicial, cole o log de erro que deseja analisar no campo de texto.
2. Clique no bot√£o "Analisar" para enviar o log para processamento.
3. Aguarde a resposta da IA, que ser√° exibida na tela.
4. Para ver o hist√≥rico de an√°lises anteriores, clique em "Hist√≥rico" na barra de navega√ß√£o.

## üîÑ Exemplos de Uso

A aplica√ß√£o inclui um bot√£o "Exemplo" que insere automaticamente um log de erro de exemplo para demonstra√ß√£o.

## üß™ Testes Unit√°rios

O projeto inclui testes unit√°rios abrangentes para garantir a qualidade e o funcionamento correto da aplica√ß√£o. Os testes cobrem:

### Componentes Testados

- **Modelo LogAnalysis**: Testes para cria√ß√£o e representa√ß√£o de string do modelo
- **Fun√ß√£o build_prompt**: Testes para garantir a formata√ß√£o correta do prompt
- **View analyze_log**: Testes para requisi√ß√µes GET e POST, incluindo mock da API OpenAI e tratamento de erros
- **View history**: Testes para filtragem por endere√ßo IP e suporte ao cabe√ßalho X-Forwarded-For

### Executando os Testes

Para executar todos os testes:

```
python manage.py test
```

Para executar testes espec√≠ficos:

```
python manage.py test analyzer.tests.LogAnalysisModelTests
python manage.py test analyzer.tests.AnalyzeLogViewTests
```

### Cobertura de Testes

Os testes foram desenvolvidos para cobrir os principais fluxos da aplica√ß√£o, incluindo:
- Cria√ß√£o e valida√ß√£o de modelos
- Formata√ß√£o de prompts
- Processamento de requisi√ß√µes
- Integra√ß√£o com a API OpenAI (com mocks)
- Filtragem de dados por IP
- Tratamento de erros